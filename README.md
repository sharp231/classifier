
---

# End-to-End Image Classification App (CIFAR-10)

画像認識モデルの学習から Web アプリケーションとしてのデプロイまでを、End-to-End で実装したプロジェクトです。
ユーザーがアップロードした画像を AI が解析し、10 種類のクラス（飛行機、猫、犬など）に分類します。

## 🚀 プロジェクト概要

機械学習モデルを単に作成するだけでなく、実際の Web サービスとして稼働させるためのアーキテクチャ設計と実装を行いました。
入力画像の揺らぎ（回転、アスペクト比）吸収や、推論精度の安定化（TTA）など、実運用を想定した工夫を取り入れています。

- **開発期間:** [3ヶ月]
- **担当領域:** 企画・要件定義 / モデル構築 / Web 実装 / デプロイ (Full Cycle)

## ✨ 技術的工夫 (Key Features)

### 1. 推論精度の安定化 (Test Time Augmentation)

単一の推論ではなく、入力画像を複数の倍率（1.0, 0.8, 0.65）でクロップして推論し、その平均値を取るアンサンブル処理を実装しています。これにより、被写体の大きさや位置ズレに強い判定を実現しました。

### 2. 堅牢な前処理パイプライン

ユーザーが投稿する多様な画像に対応するための処理を実装しています。

- **EXIF 自動補正:** スマホ写真の回転情報を読み取り、正しい向きに補正。
- **Center Crop:** 単純なリサイズによる画像の歪みを防ぐため、アスペクト比を維持したまま中央を切り抜く処理を採用。

### 3.ロギング設計と可観測性 (Observability)

チーム開発および本番運用を見据え、単純な `print` 出力ではなく、Python標準の `logging` モジュールを採用しました。

- **運用監視の強化:**
  エラー発生時に「いつ」「どこで」「何が」起きたかをタイムスタンプ付きで正確に記録し、本番環境（Render）でのトラブルシューティングを迅速化します。
- **チーム開発への配慮:**
  ログフォーマットを統一（`asctime` - `levelname` - `message`）することで、他の開発者がログを見た際にも状況を把握しやすくしています。
- **環境による制御:**
  開発中は `DEBUG` レベルで詳細な変数の動きを追い、本番環境では `INFO` や `ERROR` 以上のみを出力するなど、コードを書き換えずにログレベルを柔軟に制御できる設計にしています。

### 4. 安定性を重視したアーキテクチャ

- **遅延ロード (Lazy Loading):** サーバー起動時のメモリ負荷を抑えるため、モデルのロードを初回リクエスト時（または明示的なタイミング）に行う設計を採用。
- **エラーハンドリング:** 画像形式エラーやモデルロード失敗時に、サーバーをクラッシュさせずに適切なメッセージを返す安全設計。
- **構造化ロギング (Structured Logging):** `print` デバッグを廃止し、`logging` モジュールによるログ管理を徹底。タイムスタンプとログレベル（INFO/ERROR）を明記することで、チーム開発における可読性と、本番運用時のトラブルシューティング効率（トレーサビリティ）を高めています。

## 🛠 技術スタック (Tech Stack)

| Category           | Technology                               |
| :----------------- | :--------------------------------------- |
| **ML / DL**        | Python 3, TensorFlow, Keras (CNN Model)  |
| **Backend**        | Flask (Web API & Model Serving)          |
| **Frontend**       | HTML5, Tailwind CSS, JavaScript (jQuery) |
| **Image Proc**     | Pillow (PIL), NumPy                      |
| **Infrastructure** | Render (PaaS)                            |

## 📂 ディレクトリ構成

```text
.
├── app.py      # Flaskアプリケーションエントリーポイント（推論API）
├── train_cifar10.py   # モデル学習用スクリプト
├── karas.py           # 前処理ロジック（EXIF補正等）
├── image_classifier.h5 # 学習済みモデル（バイナリ）
├── data/               # ★新規作成（.gitignore推奨）
│   ├── uploads/        # ユーザーがアップした画像
│   └── results/        # 推論ログや結果ファイル（将来用）
├── templates/         # フロントエンド（HTML）
│   ├── index.html     # アップロード画面
│   ├── result.html    # 結果表示画面
    └── layout.html    # 共通レイアウト

```

## ⚙️ ローカルでの実行方法

```bash
# 1. リポジトリのクローン
git clone [repository_url]
cd [project_name]

# 2. 依存ライブラリのインストール
pip install -r requirements.txt

# 3. モデルの学習（学習済みモデルがない場合）
python train_cifar10.py

# 4. アプリケーションの起動
python app.py

```

ブラウザで `http://127.0.0.1:5000` にアクセスしてください。

## 🔍 今後の展望 (Future Roadmap)

- GitHub Actions を用いた CI/CD パイプラインの構築

  **CI/CD パイプラインの構築**
  背景:
  現在はローカル環境でモデルを学習し、手動でRenderにデプロイしています。コードの変更や再学習のたびに手作業が発生し、デプロイミスのリスクがあります。

- フィードバック機能による継続的なデータ収集と再学習ループ（MLOps）の構築

  **フィードバック機能と MLOps ループの構築**
  背景:
  現在のモデルはCIFAR-10の固定データセットで学習していますが、実際のユーザーが投稿する画像には多様性があり、予測精度が低下する可能性があります。ユーザーのフィードバックを収集し、継続的にモデルを改善する仕組みが必要です。
  　**効果**
  ユーザーの実データでモデルが継続的に改善
  誤分類が多いクラスを重点的に学習（アクティブラーニング）

- 物体検出モデル（YOLO 等）へのリプレイス検討
  背景:
  現在の画像分類モデルは「画像全体に何が写っているか」を判定しますが、複数の物体が写っている場合や、物体の位置情報が必要な場合には対応できません。
  **YOLOv8 の導入**
  **ユースケースの拡張**
  現在: 「この画像は猫です（分類）」
  改善後: 「画像の左上に猫、右下に犬が写っています（検出）」

  **効果**
  複数物体の同時検出が可能
  物体の位置情報を提供（例: 「犬は画像の中央にいます」）

- FastAPI (Backend): 重い計算（AI 推論）、TTA（精度向上処理）を担当。
  発想からできるようにしていきたい
  **FastAPI への移行検討**
  現在のFlaskは同期処理のため、複数ユーザーからの同時リクエストに対してスケーラビリティに課題があります。また、TTA（3回の推論）のような重い処理を並列化できず、レスポンス時間が長くなっています。
  **非同期処理による高速化**
  **自動API ドキュメント生成**

````

### 補足：`requirements.txt` について

上記の `README.md` を機能させるために、以下の内容で `requirements.txt` というファイルをプロジェクトのルートに作成して一緒に保存してください。（Render へのデプロイ時にも必須となります）

**requirements.txt**

```text
Flask
tensorflow
# tensorflow-cpu  # ※Renderの無料枠等で容量制限が厳しい場合はこちらを検討
Pillow
numpy
gunicorn
werkzeug

```
````

<!-- & "C:\Users\yuuda\anaconda3\envs\ai-product\python.exe" app.py -->
